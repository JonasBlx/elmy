{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "utils_dir = os.path.join(parent_dir, \"src\", \"utils\")\n",
    "sys.path.append(utils_dir)\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from process_data import process_data\n",
    "from weighted_accuracy import weighted_accuracy_scorer\n",
    "from plot_learning_curves import plot_learning_curves\n",
    "import xgboost as xgb\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_path= os.path.join(\"..\", \"data\",\"input\", \"X_train_Wwou3IE.csv\")\n",
    "X_preprocessed = pd.read_csv(X_path, delimiter=',')\n",
    "y_path= os.path.join(\"..\", \"data\",\"input\", \"y_train_jJtXgMX.csv\")\n",
    "y_preprocessed = pd.read_csv(y_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DELIVERY_START</th>\n",
       "      <th>load_forecast</th>\n",
       "      <th>coal_power_available</th>\n",
       "      <th>gas_power_available</th>\n",
       "      <th>nucelear_power_available</th>\n",
       "      <th>wind_power_forecasts_average</th>\n",
       "      <th>solar_power_forecasts_average</th>\n",
       "      <th>wind_power_forecasts_std</th>\n",
       "      <th>solar_power_forecasts_std</th>\n",
       "      <th>predicted_spot_price</th>\n",
       "      <th>cold_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 01:00:00+00:00</td>\n",
       "      <td>49439.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11487.0</td>\n",
       "      <td>44118.0</td>\n",
       "      <td>3035.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.248348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 02:00:00+00:00</td>\n",
       "      <td>46511.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11487.0</td>\n",
       "      <td>44118.0</td>\n",
       "      <td>3143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.776532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 03:00:00+00:00</td>\n",
       "      <td>45158.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11487.0</td>\n",
       "      <td>44118.0</td>\n",
       "      <td>3288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.291112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 04:00:00+00:00</td>\n",
       "      <td>44779.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11487.0</td>\n",
       "      <td>44118.0</td>\n",
       "      <td>3447.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.127588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 05:00:00+00:00</td>\n",
       "      <td>45284.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11487.0</td>\n",
       "      <td>44118.0</td>\n",
       "      <td>3679.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.983023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10600</th>\n",
       "      <td>2023-03-29 17:00:00+00:00</td>\n",
       "      <td>50814.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11952.0</td>\n",
       "      <td>38320.0</td>\n",
       "      <td>7552.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>247.408490</td>\n",
       "      <td>7.821622</td>\n",
       "      <td>108.11</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10601</th>\n",
       "      <td>2023-03-29 18:00:00+00:00</td>\n",
       "      <td>50628.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11952.0</td>\n",
       "      <td>38320.0</td>\n",
       "      <td>8338.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>155.795012</td>\n",
       "      <td>2.534054</td>\n",
       "      <td>125.66</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10602</th>\n",
       "      <td>2023-03-29 19:00:00+00:00</td>\n",
       "      <td>48201.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11952.0</td>\n",
       "      <td>38320.0</td>\n",
       "      <td>9115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.884684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138.01</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603</th>\n",
       "      <td>2023-03-29 20:00:00+00:00</td>\n",
       "      <td>47967.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11952.0</td>\n",
       "      <td>38320.0</td>\n",
       "      <td>9636.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.669189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.74</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10604</th>\n",
       "      <td>2023-03-29 21:00:00+00:00</td>\n",
       "      <td>48444.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11952.0</td>\n",
       "      <td>38320.0</td>\n",
       "      <td>10140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.124773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.32</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10605 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DELIVERY_START  load_forecast  coal_power_available  \\\n",
       "0     2022-01-01 01:00:00+00:00        49439.0                3386.0   \n",
       "1     2022-01-01 02:00:00+00:00        46511.0                3386.0   \n",
       "2     2022-01-01 03:00:00+00:00        45158.0                3386.0   \n",
       "3     2022-01-01 04:00:00+00:00        44779.0                3386.0   \n",
       "4     2022-01-01 05:00:00+00:00        45284.0                3386.0   \n",
       "...                         ...            ...                   ...   \n",
       "10600 2023-03-29 17:00:00+00:00        50814.0                3386.0   \n",
       "10601 2023-03-29 18:00:00+00:00        50628.0                3386.0   \n",
       "10602 2023-03-29 19:00:00+00:00        48201.0                3386.0   \n",
       "10603 2023-03-29 20:00:00+00:00        47967.0                3386.0   \n",
       "10604 2023-03-29 21:00:00+00:00        48444.0                3386.0   \n",
       "\n",
       "       gas_power_available  nucelear_power_available  \\\n",
       "0                  11487.0                   44118.0   \n",
       "1                  11487.0                   44118.0   \n",
       "2                  11487.0                   44118.0   \n",
       "3                  11487.0                   44118.0   \n",
       "4                  11487.0                   44118.0   \n",
       "...                    ...                       ...   \n",
       "10600              11952.0                   38320.0   \n",
       "10601              11952.0                   38320.0   \n",
       "10602              11952.0                   38320.0   \n",
       "10603              11952.0                   38320.0   \n",
       "10604              11952.0                   38320.0   \n",
       "\n",
       "       wind_power_forecasts_average  solar_power_forecasts_average  \\\n",
       "0                            3035.0                            0.0   \n",
       "1                            3143.0                            0.0   \n",
       "2                            3288.0                            0.0   \n",
       "3                            3447.0                            0.0   \n",
       "4                            3679.0                            0.0   \n",
       "...                             ...                            ...   \n",
       "10600                        7552.0                          651.0   \n",
       "10601                        8338.0                          109.0   \n",
       "10602                        9115.0                            0.0   \n",
       "10603                        9636.0                            0.0   \n",
       "10604                       10140.0                            0.0   \n",
       "\n",
       "       wind_power_forecasts_std  solar_power_forecasts_std  \\\n",
       "0                     79.248348                   0.000000   \n",
       "1                     61.776532                   0.000000   \n",
       "2                     44.291112                   0.000000   \n",
       "3                     36.127588                   0.000000   \n",
       "4                     30.983023                   0.000000   \n",
       "...                         ...                        ...   \n",
       "10600                247.408490                   7.821622   \n",
       "10601                155.795012                   2.534054   \n",
       "10602                126.884684                   0.000000   \n",
       "10603                156.669189                   0.000000   \n",
       "10604                204.124773                   0.000000   \n",
       "\n",
       "       predicted_spot_price  cold_rate  \n",
       "0                       NaN        100  \n",
       "1                       NaN        100  \n",
       "2                       NaN        100  \n",
       "3                       NaN        100  \n",
       "4                       NaN        100  \n",
       "...                     ...        ...  \n",
       "10600                108.11         70  \n",
       "10601                125.66         70  \n",
       "10602                138.01         70  \n",
       "10603                136.74         70  \n",
       "10604                120.32         70  \n",
       "\n",
       "[10605 rows x 11 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cold_rate = {\n",
    "    1: 100,  # January\n",
    "    2: 90,   # February\n",
    "    3: 70,   # March\n",
    "    4: 50,   # April\n",
    "    5: 30,   # May\n",
    "    6: 10,   # June\n",
    "    7: 0,    # July\n",
    "    8: 5,    # August\n",
    "    9: 20,   # September\n",
    "    10: 40,  # October\n",
    "    11: 60,  # November\n",
    "    12: 80   # December\n",
    "}\n",
    "\n",
    "X_preprocessed['DELIVERY_START'] = pd.to_datetime(X_preprocessed['DELIVERY_START'], utc = True)\n",
    "\n",
    "X_preprocessed['month'] = X_preprocessed['DELIVERY_START'].dt.month\n",
    "X_preprocessed['cold_rate'] = X_preprocessed['month'].map(cold_rate)\n",
    "X_preprocessed.drop('month', axis=1, inplace=True)\n",
    "\n",
    "X_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = process_data(X_preprocessed.copy(deep=True), \"predicted_spot_price\", None, \"standard\")\n",
    "y = process_data(y_preprocessed.copy(deep=True), None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.00, Training MSE: 1554.19\n",
      "Testing R^2: 0.01, Testing MSE: 998.38\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training R^2: {train_r2:.2f}, Training MSE: {train_mse:.2f}\")\n",
    "print(f\"Testing R^2: {test_r2:.2f}, Testing MSE: {test_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_learning_curves(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [23.91247996 49.98194333 57.22693659 27.09167125 16.98709076]\n",
      "Mean RMSE: 35.04002437915392\n",
      "Standard deviation: 15.674354785500233\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert scores to positive to represent Mean Squared Error (MSE)\n",
    "mse_scores = -scores\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [23.70459668 49.7431715  57.14180623 27.0065     16.94964291]\n",
      "Mean RMSE: 34.90914346170718\n",
      "Standard deviation: 15.651689902173006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(alpha = 1000)\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert scores to positive to represent Mean Squared Error (MSE)\n",
    "mse_scores = -scores\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.02, Training MSE: 1524.58\n",
      "Testing R^2: 0.01, Testing MSE: 1002.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_poly = poly_features.transform(X)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "y_train_pred = model.predict(X_train_poly)\n",
    "y_test_pred = model.predict(X_test_poly)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training R^2: {train_r2:.2f}, Training MSE: {train_mse:.2f}\")\n",
    "print(f\"Testing R^2: {test_r2:.2f}, Testing MSE: {test_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_learning_curves(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [29.33080911 51.35939985 61.05343202 29.3070203  20.57925275]\n",
      "Mean RMSE: 38.32598280545683\n",
      "Standard deviation: 15.255216614675247\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X_poly, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert scores to positive to represent Mean Squared Error (MSE)\n",
    "mse_scores = -scores\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.00, Training MSE: 1560.98\n",
      "Testing R^2: -0.00, Testing MSE: 1011.16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X_train, y_train, X_test, and y_test are already defined\n",
    "\n",
    "# Transforming the data to include polynomial features\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "# Initializing the Ridge regression model with regularization strength alpha\n",
    "# Note: You can adjust the alpha value to see how it affects the model's performance\n",
    "alpha = 100000000  # This is a common starting point for regularization strength\n",
    "ridge_model = Ridge(alpha=alpha)\n",
    "\n",
    "# Fitting the model to the polynomial features\n",
    "ridge_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predicting on both training and testing sets\n",
    "y_train_pred = ridge_model.predict(X_train_poly)\n",
    "y_test_pred = ridge_model.predict(X_test_poly)\n",
    "\n",
    "# Calculating R^2 and Mean Squared Error (MSE) for both training and testing sets\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training R^2: {train_r2:.2f}, Training MSE: {train_mse:.2f}\")\n",
    "print(f\"Testing R^2: {test_r2:.2f}, Testing MSE: {test_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [23.41873371 49.33468324 57.09980814 27.09802576 16.9203883 ]\n",
      "Mean RMSE: 34.77432783160903\n",
      "Standard deviation: 15.601726242580124\n"
     ]
    }
   ],
   "source": [
    "ridge_model = Ridge(alpha=alpha)\n",
    "scores = cross_val_score(ridge_model, X_poly, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert scores to positive to represent Mean Squared Error (MSE)\n",
    "mse_scores = -scores\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 38.19, Training R^2: 0.07\n",
      "Testing RMSE: 30.86, Testing R^2: 0.06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Create a decision tree regressor model\n",
    "tree_reg = DecisionTreeRegressor(max_depth=5)  # You can adjust the max_depth as needed\n",
    "\n",
    "# Fit the model to the training data\n",
    "tree_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training set and the test set\n",
    "y_train_pred = tree_reg.predict(X_train)\n",
    "y_test_pred = tree_reg.predict(X_test)\n",
    "\n",
    "# Calculate the performance metrics\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"Training RMSE: {train_rmse:.2f}, Training R^2: {train_r2:.2f}\")\n",
    "print(f\"Testing RMSE: {test_rmse:.2f}, Testing R^2: {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [23.42558606 49.70112953 57.06211571 27.09356241 16.90664129]\n",
      "Mean RMSE: 34.83780700124896\n",
      "Standard deviation: 15.6625481264992\n"
     ]
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor(max_depth=2)\n",
    "scores = cross_val_score(tree_reg, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert scores to positive to represent Mean Squared Error (MSE)\n",
    "mse_scores = -scores\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 746.17\n",
      "R-squared (R2): 0.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\"\"\"# Generate a synthetic regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = gbr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Initialize the Gradient Boosting Regressor\\ngbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\\n\\n# Perform 5-fold cross-validation and compute the cross-validation scores\\n# Note: By default, cross_val_score uses R^2 as the score to evaluate. \\n# For MSE, we need to specify \\'neg_mean_squared_error\\' as the scoring parameter,\\n# and later convert it to positive MSE scores.\\ncv_scores = cross_val_score(gbr, X, y, cv=5, scoring=\\'neg_mean_squared_error\\')\\n\\n# Convert negative MSE scores to positive values\\nmse_scores = -cv_scores\\n\\n# Calculate the root mean squared error (RMSE) from MSE scores\\nrmse_scores = np.sqrt(mse_scores)\\n\\nprint(\"Cross-validation RMSE scores:\", rmse_scores)\\nprint(\"Mean RMSE:\", rmse_scores.mean())\\nprint(\"Standard deviation of RMSE:\", rmse_scores.std())'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "# Initialize the Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation and compute the cross-validation scores\n",
    "# Note: By default, cross_val_score uses R^2 as the score to evaluate. \n",
    "# For MSE, we need to specify 'neg_mean_squared_error' as the scoring parameter,\n",
    "# and later convert it to positive MSE scores.\n",
    "cv_scores = cross_val_score(gbr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE scores to positive values\n",
    "mse_scores = -cv_scores\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation of RMSE:\", rmse_scores.std())\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Initialize the Gradient Boosting Regressor with increased complexity\\ngbr_complex = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42)\\n\\n# Perform 5-fold cross-validation and compute the cross-validation scores\\ncv_scores_complex = cross_val_score(gbr_complex, X, y, cv=5, scoring=\\'neg_mean_squared_error\\')\\n\\n# Convert negative MSE scores to positive values\\nmse_scores_complex = -cv_scores_complex\\n\\n# Calculate the root mean squared error (RMSE) from MSE scores\\nrmse_scores_complex = np.sqrt(mse_scores_complex)\\n\\nprint(\"Cross-validation RMSE scores:\", rmse_scores_complex)\\nprint(\"Mean RMSE:\", rmse_scores_complex.mean())\\nprint(\"Standard deviation of RMSE:\", rmse_scores_complex.std())'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"# Initialize the Gradient Boosting Regressor with increased complexity\n",
    "gbr_complex = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation and compute the cross-validation scores\n",
    "cv_scores_complex = cross_val_score(gbr_complex, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE scores to positive values\n",
    "mse_scores_complex = -cv_scores_complex\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE scores\n",
    "rmse_scores_complex = np.sqrt(mse_scores_complex)\n",
    "\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores_complex)\n",
    "print(\"Mean RMSE:\", rmse_scores_complex.mean())\n",
    "print(\"Standard deviation of RMSE:\", rmse_scores_complex.std())\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [24.75300424 50.09622651 57.48569086 27.27478572 17.07339804]\n",
      "Mean RMSE: 35.33662107489588\n",
      "Standard deviation of RMSE: 15.61395975016201\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor with increased complexity\n",
    "gbr_complex = GradientBoostingRegressor(n_estimators=50, learning_rate=0.1, max_depth=2, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation and compute the cross-validation scores\n",
    "cv_scores_complex = cross_val_score(gbr_complex, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE scores to positive values\n",
    "mse_scores_complex = -cv_scores_complex\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE scores\n",
    "rmse_scores_complex = np.sqrt(mse_scores_complex)\n",
    "\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores_complex)\n",
    "print(\"Mean RMSE:\", rmse_scores_complex.mean())\n",
    "print(\"Standard deviation of RMSE:\", rmse_scores_complex.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the more complex model and the easier model, we deduce if we were overfitting or not : We were overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [24.75300424 50.09622651 57.48569086 27.27478572 17.07339804]\n",
      "Mean RMSE: 35.33662107489588\n",
      "Standard deviation of RMSE: 15.61395975016201\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor with increased complexity\n",
    "gbr_complex = GradientBoostingRegressor(n_estimators=50, learning_rate=0.1, max_depth=2, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation and compute the cross-validation scores\n",
    "cv_scores_complex = cross_val_score(gbr_complex, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE scores to positive values\n",
    "mse_scores_complex = -cv_scores_complex\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE scores\n",
    "rmse_scores_complex = np.sqrt(mse_scores_complex)\n",
    "\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores_complex)\n",
    "print(\"Mean RMSE:\", rmse_scores_complex.mean())\n",
    "print(\"Standard deviation of RMSE:\", rmse_scores_complex.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'n_estimators': [150, 250],  # Number of boosting stages to be run\n",
    "'learning_rate': [0.15, 0.25],  # Learning rate shrinks the contribution of each tree\n",
    "'max_depth': [5, 6],  # Maximum depth of the individual regression estimators\n",
    "'min_samples_split': [1, 3],  # The minimum number of samples required to split an internal node\n",
    "'min_samples_leaf': [2, 3],\n",
    ">Best parameters found:  {'learning_rate': 0.15, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 250}\n",
    "Best cross-validation score (negative MSE):  -973.8543644050851\n",
    "Mean Squared Error (MSE) with best parameters: 493.66\n",
    "R-squared (R2) with best parameters: 0.51\n",
    "\n",
    "    'n_estimators': [200, 250],  # Number of boosting stages to be run\n",
    "    'learning_rate': [0.15, 0.2],  # Learning rate shrinks the contribution of each tree\n",
    "    'max_depth': [5, 6],  # Maximum depth of the individual regression estimators\n",
    "    'min_samples_split': [2, 3],  # The minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [2],\n",
    "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
    "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
    "  y = column_or_1d(y, warn=True)\n",
    "Best parameters found:  {'learning_rate': 0.2, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 250}\n",
    "Best cross-validation score (negative MSE):  -971.1968402606602\n",
    "Mean Squared Error (MSE) with best parameters: 509.69\n",
    "R-squared (R2) with best parameters: 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grid_search.fit(X_train, y_train)\\n\\n# Print the best parameters and the corresponding score\\nprint(\"Best parameters found: \", grid_search.best_params_)\\nprint(\"Best cross-validation score (negative MSE): \", grid_search.best_score_)\\n\\n# Predict on the testing data using the best found parameters\\ny_pred = grid_search.predict(X_test)\\n\\n# Evaluate the model with the best parameters\\nmse = mean_squared_error(y_test, y_pred)\\nr2 = r2_score(y_test, y_pred)\\n\\nprint(f\"Mean Squared Error (MSE) with best parameters: {mse:.2f}\")\\nprint(f\"R-squared (R2) with best parameters: {r2:.2f}\")'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 250],  # Number of boosting stages to be run\n",
    "    'learning_rate': [0.15, 0.2],  # Learning rate shrinks the contribution of each tree\n",
    "    'max_depth': [5, 6],  # Maximum depth of the individual regression estimators\n",
    "    'min_samples_split': [2, 3],  # The minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [2],  # The minimum number of samples required to be at a leaf node\n",
    "}\n",
    "# > learning_rate': 0.2, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Initialize the Grid Search model\n",
    "grid_search = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the Grid Search model\n",
    "\"\"\"grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score (negative MSE): \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the testing data using the best found parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model with the best parameters\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE) with best parameters: {mse:.2f}\")\n",
    "print(f\"R-squared (R2) with best parameters: {r2:.2f}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[147], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m gbr_complex \u001b[38;5;241m=\u001b[39m GradientBoostingRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m250\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, min_samples_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, min_samples_leaf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Perform 5-fold cross-validation and compute the cross-validation scores\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m cv_scores_complex \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgbr_complex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneg_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Convert negative MSE scores to positive values\u001b[39;00m\n\u001b[0;32m     14\u001b[0m mse_scores_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mcv_scores_complex\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:532\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    531\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 532\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:610\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    603\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    604\u001b[0m             y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    605\u001b[0m             raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    606\u001b[0m             sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    607\u001b[0m         )\n\u001b[0;32m    609\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 610\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:245\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    242\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    244\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 245\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    248\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    249\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    250\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    258\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor with increased complexity\n",
    "# learning_rate': 0.2, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 250\n",
    "gbr_complex = GradientBoostingRegressor(n_estimators=250, learning_rate=0.2, max_depth=6, random_state=42, min_samples_split = 2, min_samples_leaf = 2)\n",
    "\n",
    "# Perform 5-fold cross-validation and compute the cross-validation scores\n",
    "cv_scores_complex = cross_val_score(gbr_complex, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE scores to positive values\n",
    "mse_scores_complex = -cv_scores_complex\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE scores\n",
    "rmse_scores_complex = np.sqrt(mse_scores_complex)\n",
    "\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores_complex)\n",
    "print(\"Mean RMSE:\", rmse_scores_complex.mean())\n",
    "print(\"Standard deviation of RMSE:\", rmse_scores_complex.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [23.63519043 49.65357997 57.065247   27.11044023 17.3584948 ]\n",
      "Mean RMSE: 34.96459048593854\n",
      "Standard deviation of RMSE: 15.519168904019235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Support Vector Regressor\n",
    "svr = SVR(kernel='linear')\n",
    "\n",
    "# Perform 5-fold cross-validation and compute the cross-validation scores\n",
    "# Note: By default, cross_val_score uses R^2 as the score to evaluate. \n",
    "# For MSE, we need to specify 'neg_mean_squared_error' as the scoring parameter,\n",
    "# and later convert it to positive MSE scores.\n",
    "cv_scores = cross_val_score(svr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE scores to positive values\n",
    "mse_scores = -cv_scores\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation of RMSE:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:38.66813\tvalidation_1-rmse:30.95246\n",
      "[1]\tvalidation_0-rmse:37.52104\tvalidation_1-rmse:30.39418\n",
      "[2]\tvalidation_0-rmse:35.94488\tvalidation_1-rmse:30.52696\n",
      "[3]\tvalidation_0-rmse:34.75663\tvalidation_1-rmse:29.42517\n",
      "[4]\tvalidation_0-rmse:31.82708\tvalidation_1-rmse:28.95460\n",
      "[5]\tvalidation_0-rmse:29.68750\tvalidation_1-rmse:28.33683\n",
      "[6]\tvalidation_0-rmse:27.97336\tvalidation_1-rmse:28.08091\n",
      "[7]\tvalidation_0-rmse:27.60334\tvalidation_1-rmse:27.82393\n",
      "[8]\tvalidation_0-rmse:26.62542\tvalidation_1-rmse:27.70515\n",
      "[9]\tvalidation_0-rmse:25.53083\tvalidation_1-rmse:27.43615\n",
      "[10]\tvalidation_0-rmse:25.28164\tvalidation_1-rmse:27.27962\n",
      "[11]\tvalidation_0-rmse:24.47325\tvalidation_1-rmse:27.07921\n",
      "[12]\tvalidation_0-rmse:24.06108\tvalidation_1-rmse:27.01435\n",
      "[13]\tvalidation_0-rmse:23.87718\tvalidation_1-rmse:26.91239\n",
      "[14]\tvalidation_0-rmse:23.46667\tvalidation_1-rmse:26.78130\n",
      "[15]\tvalidation_0-rmse:23.06399\tvalidation_1-rmse:26.68756\n",
      "[16]\tvalidation_0-rmse:22.74354\tvalidation_1-rmse:26.56820\n",
      "[17]\tvalidation_0-rmse:22.16881\tvalidation_1-rmse:26.41833\n",
      "[18]\tvalidation_0-rmse:21.64702\tvalidation_1-rmse:26.14997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [17:40:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"n_estimator\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\tvalidation_0-rmse:21.49061\tvalidation_1-rmse:26.07209\n",
      "[20]\tvalidation_0-rmse:21.18977\tvalidation_1-rmse:25.97604\n",
      "[21]\tvalidation_0-rmse:21.05082\tvalidation_1-rmse:25.98183\n",
      "[22]\tvalidation_0-rmse:20.94272\tvalidation_1-rmse:25.82827\n",
      "[23]\tvalidation_0-rmse:20.40630\tvalidation_1-rmse:25.56626\n",
      "[24]\tvalidation_0-rmse:20.13283\tvalidation_1-rmse:25.47315\n",
      "[25]\tvalidation_0-rmse:20.05416\tvalidation_1-rmse:25.45844\n",
      "[26]\tvalidation_0-rmse:19.58857\tvalidation_1-rmse:25.23729\n",
      "[27]\tvalidation_0-rmse:19.44111\tvalidation_1-rmse:25.17743\n",
      "[28]\tvalidation_0-rmse:19.24379\tvalidation_1-rmse:25.07779\n",
      "[29]\tvalidation_0-rmse:18.87212\tvalidation_1-rmse:25.12871\n",
      "[30]\tvalidation_0-rmse:18.41335\tvalidation_1-rmse:25.03082\n",
      "[31]\tvalidation_0-rmse:18.16267\tvalidation_1-rmse:24.88405\n",
      "[32]\tvalidation_0-rmse:17.87451\tvalidation_1-rmse:24.72892\n",
      "[33]\tvalidation_0-rmse:17.64802\tvalidation_1-rmse:24.64494\n",
      "[34]\tvalidation_0-rmse:17.50318\tvalidation_1-rmse:24.52993\n",
      "[35]\tvalidation_0-rmse:17.35563\tvalidation_1-rmse:24.46586\n",
      "[36]\tvalidation_0-rmse:17.28874\tvalidation_1-rmse:24.49711\n",
      "[37]\tvalidation_0-rmse:16.98130\tvalidation_1-rmse:24.49690\n",
      "[38]\tvalidation_0-rmse:16.94224\tvalidation_1-rmse:24.48478\n",
      "[39]\tvalidation_0-rmse:16.82811\tvalidation_1-rmse:24.48214\n",
      "[40]\tvalidation_0-rmse:16.67995\tvalidation_1-rmse:24.42311\n",
      "[41]\tvalidation_0-rmse:16.63483\tvalidation_1-rmse:24.41015\n",
      "[42]\tvalidation_0-rmse:16.58512\tvalidation_1-rmse:24.38939\n",
      "[43]\tvalidation_0-rmse:16.45011\tvalidation_1-rmse:24.37944\n",
      "[44]\tvalidation_0-rmse:16.30009\tvalidation_1-rmse:24.36849\n",
      "[45]\tvalidation_0-rmse:16.18095\tvalidation_1-rmse:24.36145\n",
      "[46]\tvalidation_0-rmse:16.05802\tvalidation_1-rmse:24.37588\n",
      "[47]\tvalidation_0-rmse:15.98463\tvalidation_1-rmse:24.36089\n",
      "[48]\tvalidation_0-rmse:15.86712\tvalidation_1-rmse:24.34682\n",
      "[49]\tvalidation_0-rmse:15.77376\tvalidation_1-rmse:24.32751\n",
      "[50]\tvalidation_0-rmse:15.64621\tvalidation_1-rmse:24.31870\n",
      "[51]\tvalidation_0-rmse:15.53732\tvalidation_1-rmse:24.33457\n",
      "[52]\tvalidation_0-rmse:15.32810\tvalidation_1-rmse:24.26233\n",
      "[53]\tvalidation_0-rmse:15.22153\tvalidation_1-rmse:24.26204\n",
      "[54]\tvalidation_0-rmse:15.11323\tvalidation_1-rmse:24.22767\n",
      "[55]\tvalidation_0-rmse:14.95346\tvalidation_1-rmse:24.17469\n",
      "[56]\tvalidation_0-rmse:14.77930\tvalidation_1-rmse:24.10837\n",
      "[57]\tvalidation_0-rmse:14.73962\tvalidation_1-rmse:24.12666\n",
      "[58]\tvalidation_0-rmse:14.62729\tvalidation_1-rmse:24.12166\n",
      "[59]\tvalidation_0-rmse:14.55835\tvalidation_1-rmse:24.07283\n",
      "[60]\tvalidation_0-rmse:14.49040\tvalidation_1-rmse:24.06626\n",
      "[61]\tvalidation_0-rmse:14.41966\tvalidation_1-rmse:24.06726\n",
      "[62]\tvalidation_0-rmse:14.37342\tvalidation_1-rmse:24.06277\n",
      "[63]\tvalidation_0-rmse:14.30609\tvalidation_1-rmse:24.06540\n",
      "[64]\tvalidation_0-rmse:14.26621\tvalidation_1-rmse:24.05837\n",
      "[65]\tvalidation_0-rmse:14.20453\tvalidation_1-rmse:24.04632\n",
      "[66]\tvalidation_0-rmse:14.16739\tvalidation_1-rmse:24.04801\n",
      "[67]\tvalidation_0-rmse:14.11863\tvalidation_1-rmse:24.04131\n",
      "[68]\tvalidation_0-rmse:14.05144\tvalidation_1-rmse:24.01868\n",
      "[69]\tvalidation_0-rmse:13.94699\tvalidation_1-rmse:24.02876\n",
      "[70]\tvalidation_0-rmse:13.88193\tvalidation_1-rmse:24.04529\n",
      "[71]\tvalidation_0-rmse:13.81588\tvalidation_1-rmse:24.02951\n",
      "[72]\tvalidation_0-rmse:13.77041\tvalidation_1-rmse:24.03394\n",
      "[73]\tvalidation_0-rmse:13.67513\tvalidation_1-rmse:24.02222\n",
      "[74]\tvalidation_0-rmse:13.63858\tvalidation_1-rmse:24.00310\n",
      "[75]\tvalidation_0-rmse:13.60056\tvalidation_1-rmse:24.01448\n",
      "[76]\tvalidation_0-rmse:13.56947\tvalidation_1-rmse:24.02609\n",
      "[77]\tvalidation_0-rmse:13.54589\tvalidation_1-rmse:24.02251\n",
      "[78]\tvalidation_0-rmse:13.49604\tvalidation_1-rmse:24.02245\n",
      "[79]\tvalidation_0-rmse:13.35225\tvalidation_1-rmse:23.96795\n",
      "[80]\tvalidation_0-rmse:13.29993\tvalidation_1-rmse:23.95829\n",
      "[81]\tvalidation_0-rmse:13.24956\tvalidation_1-rmse:23.95063\n",
      "[82]\tvalidation_0-rmse:13.22265\tvalidation_1-rmse:23.94522\n",
      "[83]\tvalidation_0-rmse:13.10857\tvalidation_1-rmse:23.98446\n",
      "[84]\tvalidation_0-rmse:13.07884\tvalidation_1-rmse:23.95123\n",
      "[85]\tvalidation_0-rmse:13.02183\tvalidation_1-rmse:23.93323\n",
      "[86]\tvalidation_0-rmse:12.92710\tvalidation_1-rmse:23.92989\n",
      "[87]\tvalidation_0-rmse:12.89949\tvalidation_1-rmse:23.91065\n",
      "[88]\tvalidation_0-rmse:12.81185\tvalidation_1-rmse:23.88966\n",
      "[89]\tvalidation_0-rmse:12.71561\tvalidation_1-rmse:23.87348\n",
      "[90]\tvalidation_0-rmse:12.67780\tvalidation_1-rmse:23.86504\n",
      "[91]\tvalidation_0-rmse:12.65432\tvalidation_1-rmse:23.86811\n",
      "[92]\tvalidation_0-rmse:12.53429\tvalidation_1-rmse:23.86305\n",
      "[93]\tvalidation_0-rmse:12.42449\tvalidation_1-rmse:23.86805\n",
      "[94]\tvalidation_0-rmse:12.35119\tvalidation_1-rmse:23.85075\n",
      "[95]\tvalidation_0-rmse:12.30738\tvalidation_1-rmse:23.83752\n",
      "[96]\tvalidation_0-rmse:12.27342\tvalidation_1-rmse:23.82981\n",
      "[97]\tvalidation_0-rmse:12.19012\tvalidation_1-rmse:23.80050\n",
      "[98]\tvalidation_0-rmse:12.15469\tvalidation_1-rmse:23.80598\n",
      "[99]\tvalidation_0-rmse:12.09378\tvalidation_1-rmse:23.80421\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimator=1000, n_estimators=None,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimator=1000, n_estimators=None,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimator=1000, n_estimators=None,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = xgb.XGBRegressor(n_estimator = 1000)\n",
    "reg.fit(X_train, y_train,\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)],\n",
    "        verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(566.6401968003687, 0.43933926268869183)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [38.34562361 55.19911016 59.35552329 31.7381651  26.79500605]\n",
      "Mean RMSE: 42.2866856414645\n",
      "Standard deviation of RMSE: 12.844230749132231\n"
     ]
    }
   ],
   "source": [
    "reg = xgb.XGBRegressor(n_estimator = 1000)\n",
    "\"\"\"reg.fit(X_train, y_train,\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)],\n",
    "        verbose = True)\"\"\"\n",
    "cv_scores_complex = cross_val_score(gbr_complex, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE scores to positive values\n",
    "mse_scores_complex = -cv_scores_complex\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE scores\n",
    "rmse_scores_complex = np.sqrt(mse_scores_complex)\n",
    "\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores_complex)\n",
    "print(\"Mean RMSE:\", rmse_scores_complex.mean())\n",
    "print(\"Standard deviation of RMSE:\", rmse_scores_complex.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elmy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
