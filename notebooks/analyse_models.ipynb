{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "utils_dir = os.path.join(parent_dir, \"src\", \"utils\")\n",
    "sys.path.append(utils_dir)\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from process_data import process_data\n",
    "from weighted_accuracy import weighted_accuracy_scorer\n",
    "from plot_learning_curves import plot_learning_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_path= os.path.join(\"..\", \"data\",\"input\", \"X_train_Wwou3IE.csv\")\n",
    "X_preprocessed = pd.read_csv(X_path, delimiter=',')\n",
    "y_path= os.path.join(\"..\", \"data\",\"input\", \"y_train_jJtXgMX.csv\")\n",
    "y_preprocessed = pd.read_csv(y_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DELIVERY_START</th>\n",
       "      <th>load_forecast</th>\n",
       "      <th>coal_power_available</th>\n",
       "      <th>gas_power_available</th>\n",
       "      <th>nucelear_power_available</th>\n",
       "      <th>wind_power_forecasts_average</th>\n",
       "      <th>solar_power_forecasts_average</th>\n",
       "      <th>wind_power_forecasts_std</th>\n",
       "      <th>solar_power_forecasts_std</th>\n",
       "      <th>predicted_spot_price</th>\n",
       "      <th>cold_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 01:00:00+00:00</td>\n",
       "      <td>49439.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11487.0</td>\n",
       "      <td>44118.0</td>\n",
       "      <td>3035.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.248348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 02:00:00+00:00</td>\n",
       "      <td>46511.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11487.0</td>\n",
       "      <td>44118.0</td>\n",
       "      <td>3143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.776532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 03:00:00+00:00</td>\n",
       "      <td>45158.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11487.0</td>\n",
       "      <td>44118.0</td>\n",
       "      <td>3288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.291112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 04:00:00+00:00</td>\n",
       "      <td>44779.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11487.0</td>\n",
       "      <td>44118.0</td>\n",
       "      <td>3447.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.127588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 05:00:00+00:00</td>\n",
       "      <td>45284.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11487.0</td>\n",
       "      <td>44118.0</td>\n",
       "      <td>3679.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.983023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10600</th>\n",
       "      <td>2023-03-29 17:00:00+00:00</td>\n",
       "      <td>50814.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11952.0</td>\n",
       "      <td>38320.0</td>\n",
       "      <td>7552.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>247.408490</td>\n",
       "      <td>7.821622</td>\n",
       "      <td>108.11</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10601</th>\n",
       "      <td>2023-03-29 18:00:00+00:00</td>\n",
       "      <td>50628.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11952.0</td>\n",
       "      <td>38320.0</td>\n",
       "      <td>8338.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>155.795012</td>\n",
       "      <td>2.534054</td>\n",
       "      <td>125.66</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10602</th>\n",
       "      <td>2023-03-29 19:00:00+00:00</td>\n",
       "      <td>48201.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11952.0</td>\n",
       "      <td>38320.0</td>\n",
       "      <td>9115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.884684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138.01</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603</th>\n",
       "      <td>2023-03-29 20:00:00+00:00</td>\n",
       "      <td>47967.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11952.0</td>\n",
       "      <td>38320.0</td>\n",
       "      <td>9636.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.669189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.74</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10604</th>\n",
       "      <td>2023-03-29 21:00:00+00:00</td>\n",
       "      <td>48444.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>11952.0</td>\n",
       "      <td>38320.0</td>\n",
       "      <td>10140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.124773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.32</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10605 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DELIVERY_START  load_forecast  coal_power_available  \\\n",
       "0     2022-01-01 01:00:00+00:00        49439.0                3386.0   \n",
       "1     2022-01-01 02:00:00+00:00        46511.0                3386.0   \n",
       "2     2022-01-01 03:00:00+00:00        45158.0                3386.0   \n",
       "3     2022-01-01 04:00:00+00:00        44779.0                3386.0   \n",
       "4     2022-01-01 05:00:00+00:00        45284.0                3386.0   \n",
       "...                         ...            ...                   ...   \n",
       "10600 2023-03-29 17:00:00+00:00        50814.0                3386.0   \n",
       "10601 2023-03-29 18:00:00+00:00        50628.0                3386.0   \n",
       "10602 2023-03-29 19:00:00+00:00        48201.0                3386.0   \n",
       "10603 2023-03-29 20:00:00+00:00        47967.0                3386.0   \n",
       "10604 2023-03-29 21:00:00+00:00        48444.0                3386.0   \n",
       "\n",
       "       gas_power_available  nucelear_power_available  \\\n",
       "0                  11487.0                   44118.0   \n",
       "1                  11487.0                   44118.0   \n",
       "2                  11487.0                   44118.0   \n",
       "3                  11487.0                   44118.0   \n",
       "4                  11487.0                   44118.0   \n",
       "...                    ...                       ...   \n",
       "10600              11952.0                   38320.0   \n",
       "10601              11952.0                   38320.0   \n",
       "10602              11952.0                   38320.0   \n",
       "10603              11952.0                   38320.0   \n",
       "10604              11952.0                   38320.0   \n",
       "\n",
       "       wind_power_forecasts_average  solar_power_forecasts_average  \\\n",
       "0                            3035.0                            0.0   \n",
       "1                            3143.0                            0.0   \n",
       "2                            3288.0                            0.0   \n",
       "3                            3447.0                            0.0   \n",
       "4                            3679.0                            0.0   \n",
       "...                             ...                            ...   \n",
       "10600                        7552.0                          651.0   \n",
       "10601                        8338.0                          109.0   \n",
       "10602                        9115.0                            0.0   \n",
       "10603                        9636.0                            0.0   \n",
       "10604                       10140.0                            0.0   \n",
       "\n",
       "       wind_power_forecasts_std  solar_power_forecasts_std  \\\n",
       "0                     79.248348                   0.000000   \n",
       "1                     61.776532                   0.000000   \n",
       "2                     44.291112                   0.000000   \n",
       "3                     36.127588                   0.000000   \n",
       "4                     30.983023                   0.000000   \n",
       "...                         ...                        ...   \n",
       "10600                247.408490                   7.821622   \n",
       "10601                155.795012                   2.534054   \n",
       "10602                126.884684                   0.000000   \n",
       "10603                156.669189                   0.000000   \n",
       "10604                204.124773                   0.000000   \n",
       "\n",
       "       predicted_spot_price  cold_rate  \n",
       "0                       NaN        100  \n",
       "1                       NaN        100  \n",
       "2                       NaN        100  \n",
       "3                       NaN        100  \n",
       "4                       NaN        100  \n",
       "...                     ...        ...  \n",
       "10600                108.11         70  \n",
       "10601                125.66         70  \n",
       "10602                138.01         70  \n",
       "10603                136.74         70  \n",
       "10604                120.32         70  \n",
       "\n",
       "[10605 rows x 11 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cold_rate = {\n",
    "    1: 100,  # January\n",
    "    2: 90,   # February\n",
    "    3: 70,   # March\n",
    "    4: 50,   # April\n",
    "    5: 30,   # May\n",
    "    6: 10,   # June\n",
    "    7: 0,    # July\n",
    "    8: 5,    # August\n",
    "    9: 20,   # September\n",
    "    10: 40,  # October\n",
    "    11: 60,  # November\n",
    "    12: 80   # December\n",
    "}\n",
    "\n",
    "X_preprocessed['DELIVERY_START'] = pd.to_datetime(X_preprocessed['DELIVERY_START'], utc = True)\n",
    "\n",
    "X_preprocessed['month'] = X_preprocessed['DELIVERY_START'].dt.month\n",
    "X_preprocessed['cold_rate'] = X_preprocessed['month'].map(cold_rate)\n",
    "X_preprocessed.drop('month', axis=1, inplace=True)\n",
    "\n",
    "X_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = process_data(X_preprocessed.copy(deep=True), \"predicted_spot_price\", None, \"standard\")\n",
    "y = process_data(y_preprocessed.copy(deep=True), None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.00, Training MSE: 1554.19\n",
      "Testing R^2: 0.01, Testing MSE: 998.38\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training R^2: {train_r2:.2f}, Training MSE: {train_mse:.2f}\")\n",
    "print(f\"Testing R^2: {test_r2:.2f}, Testing MSE: {test_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_learning_curves(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [23.91247996 49.98194333 57.22693659 27.09167125 16.98709076]\n",
      "Mean RMSE: 35.04002437915392\n",
      "Standard deviation: 15.674354785500233\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert scores to positive to represent Mean Squared Error (MSE)\n",
    "mse_scores = -scores\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [23.70459668 49.7431715  57.14180623 27.0065     16.94964291]\n",
      "Mean RMSE: 34.90914346170718\n",
      "Standard deviation: 15.651689902173006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(alpha = 1000)\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert scores to positive to represent Mean Squared Error (MSE)\n",
    "mse_scores = -scores\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.02, Training MSE: 1524.58\n",
      "Testing R^2: 0.01, Testing MSE: 1002.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_poly = poly_features.transform(X)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "y_train_pred = model.predict(X_train_poly)\n",
    "y_test_pred = model.predict(X_test_poly)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training R^2: {train_r2:.2f}, Training MSE: {train_mse:.2f}\")\n",
    "print(f\"Testing R^2: {test_r2:.2f}, Testing MSE: {test_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_learning_curves(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [29.33080911 51.35939985 61.05343202 29.3070203  20.57925275]\n",
      "Mean RMSE: 38.32598280545683\n",
      "Standard deviation: 15.255216614675247\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X_poly, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert scores to positive to represent Mean Squared Error (MSE)\n",
    "mse_scores = -scores\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.00, Training MSE: 1560.98\n",
      "Testing R^2: -0.00, Testing MSE: 1011.16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X_train, y_train, X_test, and y_test are already defined\n",
    "\n",
    "# Transforming the data to include polynomial features\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "# Initializing the Ridge regression model with regularization strength alpha\n",
    "# Note: You can adjust the alpha value to see how it affects the model's performance\n",
    "alpha = 100000000  # This is a common starting point for regularization strength\n",
    "ridge_model = Ridge(alpha=alpha)\n",
    "\n",
    "# Fitting the model to the polynomial features\n",
    "ridge_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predicting on both training and testing sets\n",
    "y_train_pred = ridge_model.predict(X_train_poly)\n",
    "y_test_pred = ridge_model.predict(X_test_poly)\n",
    "\n",
    "# Calculating R^2 and Mean Squared Error (MSE) for both training and testing sets\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training R^2: {train_r2:.2f}, Training MSE: {train_mse:.2f}\")\n",
    "print(f\"Testing R^2: {test_r2:.2f}, Testing MSE: {test_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [23.41873371 49.33468324 57.09980814 27.09802576 16.9203883 ]\n",
      "Mean RMSE: 34.77432783160903\n",
      "Standard deviation: 15.601726242580124\n"
     ]
    }
   ],
   "source": [
    "ridge_model = Ridge(alpha=alpha)\n",
    "scores = cross_val_score(ridge_model, X_poly, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert scores to positive to represent Mean Squared Error (MSE)\n",
    "mse_scores = -scores\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 38.19, Training R^2: 0.07\n",
      "Testing RMSE: 30.86, Testing R^2: 0.06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Create a decision tree regressor model\n",
    "tree_reg = DecisionTreeRegressor(max_depth=5)  # You can adjust the max_depth as needed\n",
    "\n",
    "# Fit the model to the training data\n",
    "tree_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training set and the test set\n",
    "y_train_pred = tree_reg.predict(X_train)\n",
    "y_test_pred = tree_reg.predict(X_test)\n",
    "\n",
    "# Calculate the performance metrics\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"Training RMSE: {train_rmse:.2f}, Training R^2: {train_r2:.2f}\")\n",
    "print(f\"Testing RMSE: {test_rmse:.2f}, Testing R^2: {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [23.42558606 49.70112953 57.06211571 27.09356241 16.90664129]\n",
      "Mean RMSE: 34.83780700124896\n",
      "Standard deviation: 15.662548126499201\n"
     ]
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor(max_depth=2)\n",
    "scores = cross_val_score(tree_reg, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert scores to positive to represent Mean Squared Error (MSE)\n",
    "mse_scores = -scores\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 746.17\n",
      "R-squared (R2): 0.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\"\"\"# Generate a synthetic regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = gbr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [27.61757548 52.37860743 57.79683512 28.08778445 19.66052006]\n",
      "Mean RMSE: 37.108264504939\n",
      "Standard deviation of RMSE: 15.080227796317239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"# Generate a synthetic regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
    "\"\"\"\n",
    "# Initialize the Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation and compute the cross-validation scores\n",
    "# Note: By default, cross_val_score uses R^2 as the score to evaluate. \n",
    "# For MSE, we need to specify 'neg_mean_squared_error' as the scoring parameter,\n",
    "# and later convert it to positive MSE scores.\n",
    "cv_scores = cross_val_score(gbr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE scores to positive values\n",
    "mse_scores = -cv_scores\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation of RMSE:\", rmse_scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [34.23703866 54.29118488 58.16062986 31.05137532 22.09896375]\n",
      "Mean RMSE: 39.967838495161764\n",
      "Standard deviation of RMSE: 13.912425926595034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor with increased complexity\n",
    "gbr_complex = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation and compute the cross-validation scores\n",
    "cv_scores_complex = cross_val_score(gbr_complex, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE scores to positive values\n",
    "mse_scores_complex = -cv_scores_complex\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE scores\n",
    "rmse_scores_complex = np.sqrt(mse_scores_complex)\n",
    "\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores_complex)\n",
    "print(\"Mean RMSE:\", rmse_scores_complex.mean())\n",
    "print(\"Standard deviation of RMSE:\", rmse_scores_complex.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [24.75300424 50.09622651 57.48569086 27.27478572 17.07339804]\n",
      "Mean RMSE: 35.33662107489588\n",
      "Standard deviation of RMSE: 15.61395975016201\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor with increased complexity\n",
    "gbr_complex = GradientBoostingRegressor(n_estimators=50, learning_rate=0.1, max_depth=2, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation and compute the cross-validation scores\n",
    "cv_scores_complex = cross_val_score(gbr_complex, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE scores to positive values\n",
    "mse_scores_complex = -cv_scores_complex\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE scores\n",
    "rmse_scores_complex = np.sqrt(mse_scores_complex)\n",
    "\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores_complex)\n",
    "print(\"Mean RMSE:\", rmse_scores_complex.mean())\n",
    "print(\"Standard deviation of RMSE:\", rmse_scores_complex.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the more complex model and the easier model, we deduce if we were overfitting or not : We were overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [24.75300424 50.09622651 57.48569086 27.27478572 17.07339804]\n",
      "Mean RMSE: 35.33662107489588\n",
      "Standard deviation of RMSE: 15.61395975016201\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor with increased complexity\n",
    "gbr_complex = GradientBoostingRegressor(n_estimators=50, learning_rate=0.1, max_depth=2, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation and compute the cross-validation scores\n",
    "cv_scores_complex = cross_val_score(gbr_complex, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE scores to positive values\n",
    "mse_scores_complex = -cv_scores_complex\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE scores\n",
    "rmse_scores_complex = np.sqrt(mse_scores_complex)\n",
    "\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores_complex)\n",
    "print(\"Mean RMSE:\", rmse_scores_complex.mean())\n",
    "print(\"Standard deviation of RMSE:\", rmse_scores_complex.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of boosting stages to be run\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Learning rate shrinks the contribution of each tree\n",
    "    'max_depth': [3, 4, 5],  # Maximum depth of the individual regression estimators\n",
    "    'min_samples_split': [2, 4, 6],  # The minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 3],  # The minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Initialize the Grid Search model\n",
    "grid_search = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the Grid Search model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score (negative MSE): \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the testing data using the best found parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model with the best parameters\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE) with best parameters: {mse:.2f}\")\n",
    "print(f\"R-squared (R2) with best parameters: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Support Vector Regressor\n",
    "svr = SVR(kernel='linear')\n",
    "\n",
    "# Perform 5-fold cross-validation and compute the cross-validation scores\n",
    "# Note: By default, cross_val_score uses R^2 as the score to evaluate. \n",
    "# For MSE, we need to specify 'neg_mean_squared_error' as the scoring parameter,\n",
    "# and later convert it to positive MSE scores.\n",
    "cv_scores = cross_val_score(svr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE scores to positive values\n",
    "mse_scores = -cv_scores\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) from MSE scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard deviation of RMSE:\", rmse_scores.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elmy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
