{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "sys.path.append(parent_dir)\n",
    "utils_dir = os.path.join(parent_dir, grandparent_dir, \"src\", \"utils\")\n",
    "sys.path.append(utils_dir)\n",
    "\n",
    "from weighted_accuracy_and_tools import decompose_y, reconstruct_y, weighted_accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_path= os.path.join(\"..\", \"..\", \"data\",\"enriched_input\", \"X_train.csv\")\n",
    "X = pd.read_csv(X_path, delimiter=',')\n",
    "\n",
    "y_path= os.path.join(\"..\", \"..\", \"data\",\"enriched_input\", \"y_train.csv\")\n",
    "y = pd.read_csv(y_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.set_index(\"DELIVERY_START\", inplace=True)\n",
    "y.set_index(\"DELIVERY_START\", inplace=True)\n",
    "X.index = pd.to_datetime(X.index, utc=True)\n",
    "y.index = pd.to_datetime(y.index, utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_forecast</th>\n",
       "      <th>coal_power_available</th>\n",
       "      <th>gas_power_available</th>\n",
       "      <th>nucelear_power_available</th>\n",
       "      <th>wind_power_forecasts_average</th>\n",
       "      <th>solar_power_forecasts_average</th>\n",
       "      <th>wind_power_forecasts_std</th>\n",
       "      <th>solar_power_forecasts_std</th>\n",
       "      <th>cold_rate</th>\n",
       "      <th>av_consuption_hour</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofyear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DELIVERY_START</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00+00:00</th>\n",
       "      <td>-0.405599</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>0.049156</td>\n",
       "      <td>1.145111</td>\n",
       "      <td>-0.441788</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>-0.349637</td>\n",
       "      <td>-0.580887</td>\n",
       "      <td>-1.112973</td>\n",
       "      <td>-0.775054</td>\n",
       "      <td>-1.519140</td>\n",
       "      <td>1.002602</td>\n",
       "      <td>-1.045267</td>\n",
       "      <td>-1.287117</td>\n",
       "      <td>-0.494838</td>\n",
       "      <td>-1.406310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 02:00:00+00:00</th>\n",
       "      <td>-0.682678</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>0.049156</td>\n",
       "      <td>1.145111</td>\n",
       "      <td>-0.409506</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>-0.482002</td>\n",
       "      <td>-0.580887</td>\n",
       "      <td>-1.112973</td>\n",
       "      <td>-1.010691</td>\n",
       "      <td>-1.374581</td>\n",
       "      <td>1.002602</td>\n",
       "      <td>-1.045267</td>\n",
       "      <td>-1.287117</td>\n",
       "      <td>-0.494838</td>\n",
       "      <td>-1.406310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 03:00:00+00:00</th>\n",
       "      <td>-0.810713</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>0.049156</td>\n",
       "      <td>1.145111</td>\n",
       "      <td>-0.366164</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>-0.614471</td>\n",
       "      <td>-0.580887</td>\n",
       "      <td>-1.112973</td>\n",
       "      <td>-1.565537</td>\n",
       "      <td>-1.230023</td>\n",
       "      <td>1.002602</td>\n",
       "      <td>-1.045267</td>\n",
       "      <td>-1.287117</td>\n",
       "      <td>-0.494838</td>\n",
       "      <td>-1.406310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 04:00:00+00:00</th>\n",
       "      <td>-0.846578</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>0.049156</td>\n",
       "      <td>1.145111</td>\n",
       "      <td>-0.318637</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>-0.676317</td>\n",
       "      <td>-0.580887</td>\n",
       "      <td>-1.112973</td>\n",
       "      <td>-1.991068</td>\n",
       "      <td>-1.085464</td>\n",
       "      <td>1.002602</td>\n",
       "      <td>-1.045267</td>\n",
       "      <td>-1.287117</td>\n",
       "      <td>-0.494838</td>\n",
       "      <td>-1.406310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 05:00:00+00:00</th>\n",
       "      <td>-0.798790</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>0.049156</td>\n",
       "      <td>1.145111</td>\n",
       "      <td>-0.249289</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>-0.715292</td>\n",
       "      <td>-0.580887</td>\n",
       "      <td>-1.112973</td>\n",
       "      <td>-2.026920</td>\n",
       "      <td>-0.940906</td>\n",
       "      <td>1.002602</td>\n",
       "      <td>-1.045267</td>\n",
       "      <td>-1.287117</td>\n",
       "      <td>-0.494838</td>\n",
       "      <td>-1.406310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29 17:00:00+00:00</th>\n",
       "      <td>-0.275482</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>1.010389</td>\n",
       "      <td>0.384129</td>\n",
       "      <td>0.908396</td>\n",
       "      <td>-0.469079</td>\n",
       "      <td>0.924332</td>\n",
       "      <td>-0.399128</td>\n",
       "      <td>-0.492362</td>\n",
       "      <td>-0.085946</td>\n",
       "      <td>0.793798</td>\n",
       "      <td>-0.489343</td>\n",
       "      <td>-1.045267</td>\n",
       "      <td>-0.734099</td>\n",
       "      <td>2.020864</td>\n",
       "      <td>-0.618926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29 18:00:00+00:00</th>\n",
       "      <td>-0.293084</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>1.010389</td>\n",
       "      <td>0.384129</td>\n",
       "      <td>1.143341</td>\n",
       "      <td>-0.669539</td>\n",
       "      <td>0.230275</td>\n",
       "      <td>-0.522000</td>\n",
       "      <td>-0.492362</td>\n",
       "      <td>0.271836</td>\n",
       "      <td>0.938356</td>\n",
       "      <td>-0.489343</td>\n",
       "      <td>-1.045267</td>\n",
       "      <td>-0.734099</td>\n",
       "      <td>2.020864</td>\n",
       "      <td>-0.618926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29 19:00:00+00:00</th>\n",
       "      <td>-0.522752</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>1.010389</td>\n",
       "      <td>0.384129</td>\n",
       "      <td>1.375595</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>-0.580887</td>\n",
       "      <td>-0.492362</td>\n",
       "      <td>0.969350</td>\n",
       "      <td>1.082915</td>\n",
       "      <td>-0.489343</td>\n",
       "      <td>-1.045267</td>\n",
       "      <td>-0.734099</td>\n",
       "      <td>2.020864</td>\n",
       "      <td>-0.618926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29 20:00:00+00:00</th>\n",
       "      <td>-0.544896</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>1.010389</td>\n",
       "      <td>0.384129</td>\n",
       "      <td>1.531328</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>0.236898</td>\n",
       "      <td>-0.580887</td>\n",
       "      <td>-0.492362</td>\n",
       "      <td>0.891217</td>\n",
       "      <td>1.227474</td>\n",
       "      <td>-0.489343</td>\n",
       "      <td>-1.045267</td>\n",
       "      <td>-0.734099</td>\n",
       "      <td>2.020864</td>\n",
       "      <td>-0.618926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29 21:00:00+00:00</th>\n",
       "      <td>-0.499757</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>1.010389</td>\n",
       "      <td>0.384129</td>\n",
       "      <td>1.681980</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>0.596418</td>\n",
       "      <td>-0.580887</td>\n",
       "      <td>-0.492362</td>\n",
       "      <td>0.234253</td>\n",
       "      <td>1.372032</td>\n",
       "      <td>-0.489343</td>\n",
       "      <td>-1.045267</td>\n",
       "      <td>-0.734099</td>\n",
       "      <td>2.020864</td>\n",
       "      <td>-0.618926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10605 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           load_forecast  coal_power_available  \\\n",
       "DELIVERY_START                                                   \n",
       "2022-01-01 01:00:00+00:00      -0.405599              1.143744   \n",
       "2022-01-01 02:00:00+00:00      -0.682678              1.143744   \n",
       "2022-01-01 03:00:00+00:00      -0.810713              1.143744   \n",
       "2022-01-01 04:00:00+00:00      -0.846578              1.143744   \n",
       "2022-01-01 05:00:00+00:00      -0.798790              1.143744   \n",
       "...                                  ...                   ...   \n",
       "2023-03-29 17:00:00+00:00      -0.275482              1.143744   \n",
       "2023-03-29 18:00:00+00:00      -0.293084              1.143744   \n",
       "2023-03-29 19:00:00+00:00      -0.522752              1.143744   \n",
       "2023-03-29 20:00:00+00:00      -0.544896              1.143744   \n",
       "2023-03-29 21:00:00+00:00      -0.499757              1.143744   \n",
       "\n",
       "                           gas_power_available  nucelear_power_available  \\\n",
       "DELIVERY_START                                                             \n",
       "2022-01-01 01:00:00+00:00             0.049156                  1.145111   \n",
       "2022-01-01 02:00:00+00:00             0.049156                  1.145111   \n",
       "2022-01-01 03:00:00+00:00             0.049156                  1.145111   \n",
       "2022-01-01 04:00:00+00:00             0.049156                  1.145111   \n",
       "2022-01-01 05:00:00+00:00             0.049156                  1.145111   \n",
       "...                                        ...                       ...   \n",
       "2023-03-29 17:00:00+00:00             1.010389                  0.384129   \n",
       "2023-03-29 18:00:00+00:00             1.010389                  0.384129   \n",
       "2023-03-29 19:00:00+00:00             1.010389                  0.384129   \n",
       "2023-03-29 20:00:00+00:00             1.010389                  0.384129   \n",
       "2023-03-29 21:00:00+00:00             1.010389                  0.384129   \n",
       "\n",
       "                           wind_power_forecasts_average  \\\n",
       "DELIVERY_START                                            \n",
       "2022-01-01 01:00:00+00:00                     -0.441788   \n",
       "2022-01-01 02:00:00+00:00                     -0.409506   \n",
       "2022-01-01 03:00:00+00:00                     -0.366164   \n",
       "2022-01-01 04:00:00+00:00                     -0.318637   \n",
       "2022-01-01 05:00:00+00:00                     -0.249289   \n",
       "...                                                 ...   \n",
       "2023-03-29 17:00:00+00:00                      0.908396   \n",
       "2023-03-29 18:00:00+00:00                      1.143341   \n",
       "2023-03-29 19:00:00+00:00                      1.375595   \n",
       "2023-03-29 20:00:00+00:00                      1.531328   \n",
       "2023-03-29 21:00:00+00:00                      1.681980   \n",
       "\n",
       "                           solar_power_forecasts_average  \\\n",
       "DELIVERY_START                                             \n",
       "2022-01-01 01:00:00+00:00                      -0.709854   \n",
       "2022-01-01 02:00:00+00:00                      -0.709854   \n",
       "2022-01-01 03:00:00+00:00                      -0.709854   \n",
       "2022-01-01 04:00:00+00:00                      -0.709854   \n",
       "2022-01-01 05:00:00+00:00                      -0.709854   \n",
       "...                                                  ...   \n",
       "2023-03-29 17:00:00+00:00                      -0.469079   \n",
       "2023-03-29 18:00:00+00:00                      -0.669539   \n",
       "2023-03-29 19:00:00+00:00                      -0.709854   \n",
       "2023-03-29 20:00:00+00:00                      -0.709854   \n",
       "2023-03-29 21:00:00+00:00                      -0.709854   \n",
       "\n",
       "                           wind_power_forecasts_std  \\\n",
       "DELIVERY_START                                        \n",
       "2022-01-01 01:00:00+00:00                 -0.349637   \n",
       "2022-01-01 02:00:00+00:00                 -0.482002   \n",
       "2022-01-01 03:00:00+00:00                 -0.614471   \n",
       "2022-01-01 04:00:00+00:00                 -0.676317   \n",
       "2022-01-01 05:00:00+00:00                 -0.715292   \n",
       "...                                             ...   \n",
       "2023-03-29 17:00:00+00:00                  0.924332   \n",
       "2023-03-29 18:00:00+00:00                  0.230275   \n",
       "2023-03-29 19:00:00+00:00                  0.011252   \n",
       "2023-03-29 20:00:00+00:00                  0.236898   \n",
       "2023-03-29 21:00:00+00:00                  0.596418   \n",
       "\n",
       "                           solar_power_forecasts_std  cold_rate  \\\n",
       "DELIVERY_START                                                    \n",
       "2022-01-01 01:00:00+00:00                  -0.580887  -1.112973   \n",
       "2022-01-01 02:00:00+00:00                  -0.580887  -1.112973   \n",
       "2022-01-01 03:00:00+00:00                  -0.580887  -1.112973   \n",
       "2022-01-01 04:00:00+00:00                  -0.580887  -1.112973   \n",
       "2022-01-01 05:00:00+00:00                  -0.580887  -1.112973   \n",
       "...                                              ...        ...   \n",
       "2023-03-29 17:00:00+00:00                  -0.399128  -0.492362   \n",
       "2023-03-29 18:00:00+00:00                  -0.522000  -0.492362   \n",
       "2023-03-29 19:00:00+00:00                  -0.580887  -0.492362   \n",
       "2023-03-29 20:00:00+00:00                  -0.580887  -0.492362   \n",
       "2023-03-29 21:00:00+00:00                  -0.580887  -0.492362   \n",
       "\n",
       "                           av_consuption_hour      hour  dayofweek   quarter  \\\n",
       "DELIVERY_START                                                                 \n",
       "2022-01-01 01:00:00+00:00           -0.775054 -1.519140   1.002602 -1.045267   \n",
       "2022-01-01 02:00:00+00:00           -1.010691 -1.374581   1.002602 -1.045267   \n",
       "2022-01-01 03:00:00+00:00           -1.565537 -1.230023   1.002602 -1.045267   \n",
       "2022-01-01 04:00:00+00:00           -1.991068 -1.085464   1.002602 -1.045267   \n",
       "2022-01-01 05:00:00+00:00           -2.026920 -0.940906   1.002602 -1.045267   \n",
       "...                                       ...       ...        ...       ...   \n",
       "2023-03-29 17:00:00+00:00           -0.085946  0.793798  -0.489343 -1.045267   \n",
       "2023-03-29 18:00:00+00:00            0.271836  0.938356  -0.489343 -1.045267   \n",
       "2023-03-29 19:00:00+00:00            0.969350  1.082915  -0.489343 -1.045267   \n",
       "2023-03-29 20:00:00+00:00            0.891217  1.227474  -0.489343 -1.045267   \n",
       "2023-03-29 21:00:00+00:00            0.234253  1.372032  -0.489343 -1.045267   \n",
       "\n",
       "                              month      year  dayofyear  \n",
       "DELIVERY_START                                            \n",
       "2022-01-01 01:00:00+00:00 -1.287117 -0.494838  -1.406310  \n",
       "2022-01-01 02:00:00+00:00 -1.287117 -0.494838  -1.406310  \n",
       "2022-01-01 03:00:00+00:00 -1.287117 -0.494838  -1.406310  \n",
       "2022-01-01 04:00:00+00:00 -1.287117 -0.494838  -1.406310  \n",
       "2022-01-01 05:00:00+00:00 -1.287117 -0.494838  -1.406310  \n",
       "...                             ...       ...        ...  \n",
       "2023-03-29 17:00:00+00:00 -0.734099  2.020864  -0.618926  \n",
       "2023-03-29 18:00:00+00:00 -0.734099  2.020864  -0.618926  \n",
       "2023-03-29 19:00:00+00:00 -0.734099  2.020864  -0.618926  \n",
       "2023-03-29 20:00:00+00:00 -0.734099  2.020864  -0.618926  \n",
       "2023-03-29 21:00:00+00:00 -0.734099  2.020864  -0.618926  \n",
       "\n",
       "[10605 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_direction, y_magnitude = decompose_y(y['spot_id_delta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.249830788846133,\n",
       " ['feature_0',\n",
       "  'feature_1',\n",
       "  'feature_2',\n",
       "  'feature_4',\n",
       "  'feature_6',\n",
       "  'feature_8',\n",
       "  'feature_9',\n",
       "  'feature_10',\n",
       "  'feature_13',\n",
       "  'feature_15'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "import numpy as np\n",
    "\n",
    "# Artificially create feature names for demonstration\n",
    "feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_magnitude, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a pipeline that includes Sequential Feature Selector and Linear Regression\n",
    "sfs_linear_pipeline = Pipeline([\n",
    "    ('sfs', SequentialFeatureSelector(LinearRegression(), n_features_to_select=10, direction='forward')),\n",
    "    ('reg', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "sfs_linear_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Extract the support of the selected features\n",
    "selected_features = sfs_linear_pipeline.named_steps['sfs'].get_support()\n",
    "\n",
    "# Extract the names of the selected features\n",
    "selected_feature_names = [feature_names[i] for i in range(len(selected_features)) if selected_features[i]]\n",
    "\n",
    "# Create the voting regressor with all models, including our pipeline\n",
    "voting_reg = VotingRegressor(\n",
    "    estimators=[\n",
    "        ('sfs_linear_pipeline', sfs_linear_pipeline),\n",
    "        ('decision_tree_reg', DecisionTreeRegressor(random_state=42)),\n",
    "        ('random_forest_reg', RandomForestRegressor(random_state=42)),\n",
    "        ('gradient_boosting_reg', GradientBoostingRegressor(random_state=42)),\n",
    "        ('knn_reg', KNeighborsRegressor())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the voting regressor on the original dataset\n",
    "voting_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the voting regressor\n",
    "y_pred_voting = voting_reg.predict(X_test)\n",
    "rmse_voting = np.sqrt(mean_squared_error(y_test, y_pred_voting))\n",
    "\n",
    "rmse_voting, selected_feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['load_forecast', 'nucelear_power_available', 'wind_power_forecasts_average', 'wind_power_forecasts_std', 'hour', 'dayofweek', 'dayofyear']\n",
      "Accuracy of the voting classifier on selected features: 0.7868929750117869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X is a DataFrame and y_direction is your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_direction, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Select features based on importance\n",
    "selector = SelectFromModel(rf, prefit=True)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Get the mask of selected features\n",
    "selected_features_mask = selector.get_support()\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = X_train.columns[selected_features_mask].tolist()\n",
    "\n",
    "print(\"Selected features:\", selected_feature_names)\n",
    "\n",
    "# Re-instantiate the individual classifiers\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Create the extended voting classifier with all models, using selected features\n",
    "extended_voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('knn', knn),\n",
    "        ('dtree', dtree),\n",
    "        ('logreg', logreg),\n",
    "        ('random_forest', random_forest),\n",
    "        ('gradient_boosting', gradient_boosting)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Train the extended voting classifier on scaled data\n",
    "extended_voting_clf.fit(X_train[selected_feature_names], y_train)\n",
    "\n",
    "# Make predictions and evaluate the extended model\n",
    "y_pred = extended_voting_clf.predict(X_test[selected_feature_names])\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the voting classifier on selected features:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting features for rd forest but with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "sys.path.append(parent_dir)\n",
    "utils_dir = os.path.join(parent_dir, grandparent_dir, \"src\", \"utils\")\n",
    "sys.path.append(utils_dir)\n",
    "\n",
    "from weighted_accuracy_and_tools import decompose_y, reconstruct_y, weighted_accuracy_score\n",
    "from process_data import process_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_path= os.path.join(\"..\", \"..\", \"data\",\"original_input\", \"X_train_Wwou3IE.csv\")\n",
    "X_preprocessed = pd.read_csv(X_path, delimiter=',')\n",
    "y_path= os.path.join(\"..\", \"..\", \"data\",\"original_input\", \"y_train_jJtXgMX.csv\")\n",
    "y_preprocessed = pd.read_csv(y_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = process_data(X_preprocessed.copy(deep=True), \"predicted_spot_price\", None, \"standard\")\n",
    "y = process_data(y_preprocessed.copy(deep=True), None, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop 1, 7, 5, 2 and keep 0, 3, 4 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_forecast</th>\n",
       "      <th>coal_power_available</th>\n",
       "      <th>gas_power_available</th>\n",
       "      <th>nucelear_power_available</th>\n",
       "      <th>wind_power_forecasts_average</th>\n",
       "      <th>solar_power_forecasts_average</th>\n",
       "      <th>wind_power_forecasts_std</th>\n",
       "      <th>solar_power_forecasts_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DELIVERY_START</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00+00:00</th>\n",
       "      <td>-0.405599</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>0.049156</td>\n",
       "      <td>1.145111</td>\n",
       "      <td>-0.441788</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>-0.349637</td>\n",
       "      <td>-0.580887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 02:00:00+00:00</th>\n",
       "      <td>-0.682678</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>0.049156</td>\n",
       "      <td>1.145111</td>\n",
       "      <td>-0.409506</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>-0.482002</td>\n",
       "      <td>-0.580887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 03:00:00+00:00</th>\n",
       "      <td>-0.810713</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>0.049156</td>\n",
       "      <td>1.145111</td>\n",
       "      <td>-0.366164</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>-0.614471</td>\n",
       "      <td>-0.580887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 04:00:00+00:00</th>\n",
       "      <td>-0.846578</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>0.049156</td>\n",
       "      <td>1.145111</td>\n",
       "      <td>-0.318637</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>-0.676317</td>\n",
       "      <td>-0.580887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 05:00:00+00:00</th>\n",
       "      <td>-0.798790</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>0.049156</td>\n",
       "      <td>1.145111</td>\n",
       "      <td>-0.249289</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>-0.715292</td>\n",
       "      <td>-0.580887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29 17:00:00+00:00</th>\n",
       "      <td>-0.275482</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>1.010389</td>\n",
       "      <td>0.384129</td>\n",
       "      <td>0.908396</td>\n",
       "      <td>-0.469079</td>\n",
       "      <td>0.924332</td>\n",
       "      <td>-0.399128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29 18:00:00+00:00</th>\n",
       "      <td>-0.293084</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>1.010389</td>\n",
       "      <td>0.384129</td>\n",
       "      <td>1.143341</td>\n",
       "      <td>-0.669539</td>\n",
       "      <td>0.230275</td>\n",
       "      <td>-0.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29 19:00:00+00:00</th>\n",
       "      <td>-0.522752</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>1.010389</td>\n",
       "      <td>0.384129</td>\n",
       "      <td>1.375595</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>-0.580887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29 20:00:00+00:00</th>\n",
       "      <td>-0.544896</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>1.010389</td>\n",
       "      <td>0.384129</td>\n",
       "      <td>1.531328</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>0.236898</td>\n",
       "      <td>-0.580887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29 21:00:00+00:00</th>\n",
       "      <td>-0.499757</td>\n",
       "      <td>1.143744</td>\n",
       "      <td>1.010389</td>\n",
       "      <td>0.384129</td>\n",
       "      <td>1.681980</td>\n",
       "      <td>-0.709854</td>\n",
       "      <td>0.596418</td>\n",
       "      <td>-0.580887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10605 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           load_forecast  coal_power_available  \\\n",
       "DELIVERY_START                                                   \n",
       "2022-01-01 01:00:00+00:00      -0.405599              1.143744   \n",
       "2022-01-01 02:00:00+00:00      -0.682678              1.143744   \n",
       "2022-01-01 03:00:00+00:00      -0.810713              1.143744   \n",
       "2022-01-01 04:00:00+00:00      -0.846578              1.143744   \n",
       "2022-01-01 05:00:00+00:00      -0.798790              1.143744   \n",
       "...                                  ...                   ...   \n",
       "2023-03-29 17:00:00+00:00      -0.275482              1.143744   \n",
       "2023-03-29 18:00:00+00:00      -0.293084              1.143744   \n",
       "2023-03-29 19:00:00+00:00      -0.522752              1.143744   \n",
       "2023-03-29 20:00:00+00:00      -0.544896              1.143744   \n",
       "2023-03-29 21:00:00+00:00      -0.499757              1.143744   \n",
       "\n",
       "                           gas_power_available  nucelear_power_available  \\\n",
       "DELIVERY_START                                                             \n",
       "2022-01-01 01:00:00+00:00             0.049156                  1.145111   \n",
       "2022-01-01 02:00:00+00:00             0.049156                  1.145111   \n",
       "2022-01-01 03:00:00+00:00             0.049156                  1.145111   \n",
       "2022-01-01 04:00:00+00:00             0.049156                  1.145111   \n",
       "2022-01-01 05:00:00+00:00             0.049156                  1.145111   \n",
       "...                                        ...                       ...   \n",
       "2023-03-29 17:00:00+00:00             1.010389                  0.384129   \n",
       "2023-03-29 18:00:00+00:00             1.010389                  0.384129   \n",
       "2023-03-29 19:00:00+00:00             1.010389                  0.384129   \n",
       "2023-03-29 20:00:00+00:00             1.010389                  0.384129   \n",
       "2023-03-29 21:00:00+00:00             1.010389                  0.384129   \n",
       "\n",
       "                           wind_power_forecasts_average  \\\n",
       "DELIVERY_START                                            \n",
       "2022-01-01 01:00:00+00:00                     -0.441788   \n",
       "2022-01-01 02:00:00+00:00                     -0.409506   \n",
       "2022-01-01 03:00:00+00:00                     -0.366164   \n",
       "2022-01-01 04:00:00+00:00                     -0.318637   \n",
       "2022-01-01 05:00:00+00:00                     -0.249289   \n",
       "...                                                 ...   \n",
       "2023-03-29 17:00:00+00:00                      0.908396   \n",
       "2023-03-29 18:00:00+00:00                      1.143341   \n",
       "2023-03-29 19:00:00+00:00                      1.375595   \n",
       "2023-03-29 20:00:00+00:00                      1.531328   \n",
       "2023-03-29 21:00:00+00:00                      1.681980   \n",
       "\n",
       "                           solar_power_forecasts_average  \\\n",
       "DELIVERY_START                                             \n",
       "2022-01-01 01:00:00+00:00                      -0.709854   \n",
       "2022-01-01 02:00:00+00:00                      -0.709854   \n",
       "2022-01-01 03:00:00+00:00                      -0.709854   \n",
       "2022-01-01 04:00:00+00:00                      -0.709854   \n",
       "2022-01-01 05:00:00+00:00                      -0.709854   \n",
       "...                                                  ...   \n",
       "2023-03-29 17:00:00+00:00                      -0.469079   \n",
       "2023-03-29 18:00:00+00:00                      -0.669539   \n",
       "2023-03-29 19:00:00+00:00                      -0.709854   \n",
       "2023-03-29 20:00:00+00:00                      -0.709854   \n",
       "2023-03-29 21:00:00+00:00                      -0.709854   \n",
       "\n",
       "                           wind_power_forecasts_std  solar_power_forecasts_std  \n",
       "DELIVERY_START                                                                  \n",
       "2022-01-01 01:00:00+00:00                 -0.349637                  -0.580887  \n",
       "2022-01-01 02:00:00+00:00                 -0.482002                  -0.580887  \n",
       "2022-01-01 03:00:00+00:00                 -0.614471                  -0.580887  \n",
       "2022-01-01 04:00:00+00:00                 -0.676317                  -0.580887  \n",
       "2022-01-01 05:00:00+00:00                 -0.715292                  -0.580887  \n",
       "...                                             ...                        ...  \n",
       "2023-03-29 17:00:00+00:00                  0.924332                  -0.399128  \n",
       "2023-03-29 18:00:00+00:00                  0.230275                  -0.522000  \n",
       "2023-03-29 19:00:00+00:00                  0.011252                  -0.580887  \n",
       "2023-03-29 20:00:00+00:00                  0.236898                  -0.580887  \n",
       "2023-03-29 21:00:00+00:00                  0.596418                  -0.580887  \n",
       "\n",
       "[10605 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "#'feature_0', 'feature_3', 'feature_4', 'feature_6'\n",
    "# feature_4: 0.1946 feature_3: 0.1742 feature_6: 0.1740 feature_0: 0.1610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_direction, y_magnitude = decompose_y(y['spot_id_delta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with selected features: 19.270135466666048\n",
      "Selected feature names: ['feature_0', 'feature_3', 'feature_4', 'feature_6']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X, y_magnitude are your features and target variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_magnitude, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use RandomForestRegressor for feature importance assessment\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Use SelectFromModel to select features based on importance\n",
    "selector = SelectFromModel(rf, prefit=True)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Get the mask of selected features and their names\n",
    "selected_features_mask = selector.get_support()\n",
    "feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
    "selected_feature_names = [feature_names[i] for i in range(len(selected_features_mask)) if selected_features_mask[i]]\n",
    "\n",
    "# Train a new RandomForestRegressor on the selected features\n",
    "rf_selected = RandomForestRegressor(random_state=42)\n",
    "rf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred_selected = rf_selected.predict(X_test_selected)\n",
    "rmse_selected = np.sqrt(mean_squared_error(y_test, y_pred_selected))\n",
    "\n",
    "print(\"RMSE with selected features:\", rmse_selected)\n",
    "print(\"Selected feature names:\", selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\emac\\Documents\\MachineLearningAvance\\elmy\\elmy\\elmy_env\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with selected features: 0.694012258368694\n",
      "Selected feature names: ['feature_0', 'feature_3', 'feature_4', 'feature_6']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_direction, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use RandomForestClassifier for feature importance assessment\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Use SelectFromModel to select features based on importance\n",
    "selector = SelectFromModel(rf_clf, prefit=True)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Get the mask of selected features\n",
    "selected_features_mask = selector.get_support()\n",
    "\n",
    "# Assuming we know the feature names, let's generate them for this synthetic dataset\n",
    "feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
    "# Extract the names of the selected features\n",
    "selected_feature_names = [feature_names[i] for i in range(len(selected_features_mask)) if selected_features_mask[i]]\n",
    "\n",
    "# Train a new RandomForestClassifier on the selected features\n",
    "rf_clf_selected = RandomForestClassifier(random_state=42)\n",
    "rf_clf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred_selected = rf_clf_selected.predict(X_test_selected)\n",
    "accuracy_selected = accuracy_score(y_test, y_pred_selected)\n",
    "\n",
    "print(\"Accuracy with selected features:\", accuracy_selected)\n",
    "print(\"Selected feature names:\", selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_3: 0.4556\n",
      "feature_4: 0.1405\n",
      "feature_6: 0.1168\n",
      "feature_0: 0.1156\n",
      "feature_2: 0.1081\n",
      "feature_5: 0.0606\n",
      "feature_7: 0.0571\n",
      "feature_1: 0.0305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_direction, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_importances = rf.feature_importances_\n",
    "\n",
    "# DecisionTreeClassifier for feature importances\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_importances = dt.feature_importances_\n",
    "\n",
    "# Mutual Information for feature relevance\n",
    "mi = mutual_info_classif(X_train, y_train)\n",
    "mi_normalized = mi / np.max(mi)  # Normalize for comparison\n",
    "\n",
    "# Combine the importances/relevance scores\n",
    "combined_importances = (rf_importances + dt_importances + mi_normalized) / 3\n",
    "\n",
    "# Rank features and select the top ones\n",
    "num_top_features = 10  # Number of top features to select\n",
    "top_feature_indices = np.argsort(combined_importances)[-num_top_features:]\n",
    "\n",
    "# Assuming feature names are like 'feature_0', 'feature_1', etc.\n",
    "feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
    "top_feature_names_scores = [(feature_names[i], combined_importances[i]) for i in top_feature_indices]\n",
    "\n",
    "# Print top feature names with their scores\n",
    "for name, score in sorted(top_feature_names_scores, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_3: 0.4202\n",
      "feature_4: 0.1508\n",
      "feature_2: 0.1250\n",
      "feature_6: 0.1131\n",
      "feature_0: 0.1118\n",
      "feature_7: 0.0578\n",
      "feature_5: 0.0561\n",
      "feature_1: 0.0259\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming X, y_direction are your dataset and target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_direction, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Fit models\n",
    "dtree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances from tree-based models\n",
    "dt_importances = dtree.feature_importances_\n",
    "rf_importances = random_forest.feature_importances_\n",
    "gb_importances = gradient_boosting.feature_importances_\n",
    "\n",
    "# Calculate mutual information\n",
    "mi = mutual_info_classif(X_train, y_train)\n",
    "mi_normalized = mi / np.max(mi)  # Normalize for comparison\n",
    "\n",
    "# Average the importances/relevance scores including MI for all models\n",
    "combined_importances = (dt_importances + rf_importances + gb_importances + mi_normalized) / 4\n",
    "\n",
    "# Rank features and select the top ones\n",
    "num_top_features = 10  # Number of top features to select\n",
    "top_feature_indices = np.argsort(combined_importances)[-num_top_features:]\n",
    "\n",
    "# Assuming feature names are defined as follows\n",
    "feature_names = [f\"feature_{i}\" for i in range(X_train.shape[1])]\n",
    "top_feature_names_scores = [(feature_names[i], combined_importances[i]) for i in top_feature_indices]\n",
    "\n",
    "# Print top feature names with their scores\n",
    "for name, score in sorted(top_feature_names_scores, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking based on RandomForestClassifier:\n",
      "feature_4: 0.1946\n",
      "feature_3: 0.1742\n",
      "feature_6: 0.1740\n",
      "feature_0: 0.1610\n",
      "feature_5: 0.0922\n",
      "feature_7: 0.0892\n",
      "feature_2: 0.0839\n",
      "feature_1: 0.0309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming X, y_direction are your dataset and target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_direction, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "rf_importances = random_forest.feature_importances_\n",
    "\n",
    "# Rank features based on importance\n",
    "top_feature_indices = np.argsort(rf_importances)[::-1]\n",
    "\n",
    "# Assuming feature names are defined\n",
    "feature_names = [f\"feature_{i}\" for i in range(X_train.shape[1])]\n",
    "top_feature_names_scores = [(feature_names[i], rf_importances[i]) for i in top_feature_indices]\n",
    "\n",
    "# Print top feature names with their scores\n",
    "print(\"Feature ranking based on RandomForestClassifier:\")\n",
    "for name, score in top_feature_names_scores:\n",
    "    print(f\"{name}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature ranking based on RandomForestClassifier :**\n",
    "\n",
    "- feature_4: 0.1946\n",
    "- feature_3: 0.1742\n",
    "- feature_6: 0.1740\n",
    "- feature_0: 0.1610\n",
    "- feature_5: 0.0922\n",
    "- feature_7: 0.0892\n",
    "- feature_2: 0.0839\n",
    "- feature_1: 0.0309\n",
    "\n",
    "**DT, RF, GB :**\n",
    "- feature_3: 0.4202\n",
    "- feature_4: 0.1508\n",
    "- feature_2: 0.1250\n",
    "- feature_6: 0.1131\n",
    "- feature_0: 0.1118\n",
    "- feature_7: 0.0578\n",
    "- feature_5: 0.0561\n",
    "- feature_1: 0.0259\n",
    "\n",
    "**DT, RF :**\n",
    "- feature_3: 0.4556\n",
    "- feature_4: 0.1405\n",
    "- feature_6: 0.1168\n",
    "- feature_0: 0.1156\n",
    "- feature_2: 0.1081\n",
    "- feature_5: 0.0606\n",
    "- feature_7: 0.0571\n",
    "- feature_1: 0.0305\n",
    "\n",
    "Let's drop 1, 7, 5, 2 and keep 0, 3, 4 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>Decision Tree Regressor</th>\n",
       "      <th>Random Forest Regressor</th>\n",
       "      <th>Gradient Boosting Regressor</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature 3</th>\n",
       "      <td>9.951455</td>\n",
       "      <td>0.415757</td>\n",
       "      <td>0.312523</td>\n",
       "      <td>0.593523</td>\n",
       "      <td>2.818315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 0</th>\n",
       "      <td>7.724871</td>\n",
       "      <td>0.075803</td>\n",
       "      <td>0.125569</td>\n",
       "      <td>0.107122</td>\n",
       "      <td>2.008341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 1</th>\n",
       "      <td>3.073557</td>\n",
       "      <td>0.009414</td>\n",
       "      <td>0.089589</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.796735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 4</th>\n",
       "      <td>0.787786</td>\n",
       "      <td>0.258001</td>\n",
       "      <td>0.139293</td>\n",
       "      <td>0.038581</td>\n",
       "      <td>0.305915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 6</th>\n",
       "      <td>0.717280</td>\n",
       "      <td>0.118684</td>\n",
       "      <td>0.127327</td>\n",
       "      <td>0.039058</td>\n",
       "      <td>0.250587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 2</th>\n",
       "      <td>0.644038</td>\n",
       "      <td>0.044772</td>\n",
       "      <td>0.081153</td>\n",
       "      <td>0.106171</td>\n",
       "      <td>0.219033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 5</th>\n",
       "      <td>0.485039</td>\n",
       "      <td>0.043361</td>\n",
       "      <td>0.061420</td>\n",
       "      <td>0.020148</td>\n",
       "      <td>0.152492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 7</th>\n",
       "      <td>0.096829</td>\n",
       "      <td>0.034210</td>\n",
       "      <td>0.063125</td>\n",
       "      <td>0.081017</td>\n",
       "      <td>0.068795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Linear Regression  Decision Tree Regressor  \\\n",
       "Feature 3           9.951455                 0.415757   \n",
       "Feature 0           7.724871                 0.075803   \n",
       "Feature 1           3.073557                 0.009414   \n",
       "Feature 4           0.787786                 0.258001   \n",
       "Feature 6           0.717280                 0.118684   \n",
       "Feature 2           0.644038                 0.044772   \n",
       "Feature 5           0.485039                 0.043361   \n",
       "Feature 7           0.096829                 0.034210   \n",
       "\n",
       "           Random Forest Regressor  Gradient Boosting Regressor   Average  \n",
       "Feature 3                 0.312523                     0.593523  2.818315  \n",
       "Feature 0                 0.125569                     0.107122  2.008341  \n",
       "Feature 1                 0.089589                     0.014379  0.796735  \n",
       "Feature 4                 0.139293                     0.038581  0.305915  \n",
       "Feature 6                 0.127327                     0.039058  0.250587  \n",
       "Feature 2                 0.081153                     0.106171  0.219033  \n",
       "Feature 5                 0.061420                     0.020148  0.152492  \n",
       "Feature 7                 0.063125                     0.081017  0.068795  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X, y_direction are your dataset and target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_magnitude, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "# Initialize a DataFrame to store feature importances\n",
    "features = [f\"Feature {i}\" for i in range(X.shape[1])]\n",
    "importances_df = pd.DataFrame(index=features)\n",
    "\n",
    "# Train each model and collect their feature importances\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # For linear models, use absolute coefficients as a proxy for importance\n",
    "    if hasattr(model, 'coef_'):\n",
    "        importances = np.abs(model.coef_)\n",
    "    elif hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "    else:\n",
    "        importances = np.zeros(X.shape[1])  # Placeholder for models without feature importances\n",
    "    \n",
    "    importances_df[name] = importances\n",
    "\n",
    "# Calculate the average importance across all models\n",
    "importances_df['Average'] = importances_df.mean(axis=1)\n",
    "importances_df_sorted = importances_df.sort_values(by='Average', ascending=False)\n",
    "\n",
    "importances_df_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average (Scaled)</th>\n",
       "      <th>Linear Regression (Scaled)</th>\n",
       "      <th>Decision Tree Regressor (Scaled)</th>\n",
       "      <th>Random Forest Regressor (Scaled)</th>\n",
       "      <th>Gradient Boosting Regressor (Scaled)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature 3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 0</th>\n",
       "      <td>0.338262</td>\n",
       "      <td>0.774057</td>\n",
       "      <td>0.163382</td>\n",
       "      <td>0.255470</td>\n",
       "      <td>0.160139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 4</th>\n",
       "      <td>0.258449</td>\n",
       "      <td>0.070115</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.310125</td>\n",
       "      <td>0.041790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 6</th>\n",
       "      <td>0.159238</td>\n",
       "      <td>0.062960</td>\n",
       "      <td>0.268910</td>\n",
       "      <td>0.262470</td>\n",
       "      <td>0.042613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 1</th>\n",
       "      <td>0.103561</td>\n",
       "      <td>0.302064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112180</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 2</th>\n",
       "      <td>0.094906</td>\n",
       "      <td>0.055528</td>\n",
       "      <td>0.087015</td>\n",
       "      <td>0.078583</td>\n",
       "      <td>0.158497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 7</th>\n",
       "      <td>0.045719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061022</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>0.115063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 5</th>\n",
       "      <td>0.033224</td>\n",
       "      <td>0.039394</td>\n",
       "      <td>0.083542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Average (Scaled)  Linear Regression (Scaled)  \\\n",
       "Feature 3          1.000000                    1.000000   \n",
       "Feature 0          0.338262                    0.774057   \n",
       "Feature 4          0.258449                    0.070115   \n",
       "Feature 6          0.159238                    0.062960   \n",
       "Feature 1          0.103561                    0.302064   \n",
       "Feature 2          0.094906                    0.055528   \n",
       "Feature 7          0.045719                    0.000000   \n",
       "Feature 5          0.033224                    0.039394   \n",
       "\n",
       "           Decision Tree Regressor (Scaled)  Random Forest Regressor (Scaled)  \\\n",
       "Feature 3                          1.000000                          1.000000   \n",
       "Feature 0                          0.163382                          0.255470   \n",
       "Feature 4                          0.611765                          0.310125   \n",
       "Feature 6                          0.268910                          0.262470   \n",
       "Feature 1                          0.000000                          0.112180   \n",
       "Feature 2                          0.087015                          0.078583   \n",
       "Feature 7                          0.061022                          0.006791   \n",
       "Feature 5                          0.083542                          0.000000   \n",
       "\n",
       "           Gradient Boosting Regressor (Scaled)  \n",
       "Feature 3                              1.000000  \n",
       "Feature 0                              0.160139  \n",
       "Feature 4                              0.041790  \n",
       "Feature 6                              0.042613  \n",
       "Feature 1                              0.000000  \n",
       "Feature 2                              0.158497  \n",
       "Feature 7                              0.115063  \n",
       "Feature 5                              0.009962  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale feature importances for each model before averaging\n",
    "for model_name in models.keys():\n",
    "    # Reshape importances data to fit scaler input requirements and scale\n",
    "    importances_reshaped = importances_df[model_name].values.reshape(-1, 1)\n",
    "    scaled_importances = scaler.fit_transform(importances_reshaped).flatten()\n",
    "    importances_df[f\"{model_name} (Scaled)\"] = scaled_importances\n",
    "\n",
    "# Calculate the average of the scaled importances\n",
    "scaled_columns = [f\"{name} (Scaled)\" for name in models.keys()]\n",
    "importances_df['Average (Scaled)'] = importances_df[scaled_columns].mean(axis=1)\n",
    "importances_df_sorted_scaled = importances_df.sort_values(by='Average (Scaled)', ascending=False)\n",
    "\n",
    "importances_df_sorted_scaled[['Average (Scaled)'] + scaled_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feature 3</td>\n",
       "      <td>0.312523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feature 4</td>\n",
       "      <td>0.139293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feature 6</td>\n",
       "      <td>0.127327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feature 0</td>\n",
       "      <td>0.125569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feature 1</td>\n",
       "      <td>0.089589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Feature 2</td>\n",
       "      <td>0.081153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Feature 7</td>\n",
       "      <td>0.063125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Feature 5</td>\n",
       "      <td>0.061420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature  Importance\n",
       "0  Feature 3    0.312523\n",
       "1  Feature 4    0.139293\n",
       "2  Feature 6    0.127327\n",
       "3  Feature 0    0.125569\n",
       "4  Feature 1    0.089589\n",
       "5  Feature 2    0.081153\n",
       "6  Feature 7    0.063125\n",
       "7  Feature 5    0.061420"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_reg = RandomForestRegressor(random_state=42)\n",
    "random_forest_reg.fit(X_train, y_train)\n",
    "\n",
    "# Extract and rank feature importances\n",
    "feature_importances = random_forest_reg.feature_importances_\n",
    "features_sorted_indices = np.argsort(feature_importances)[::-1]  # Indices of features sorted by importance\n",
    "\n",
    "# Use the sorted indices to arrange names and importances correctly\n",
    "sorted_feature_names = [f\"Feature {i}\" for i in features_sorted_indices]\n",
    "sorted_feature_importances = feature_importances[features_sorted_indices]\n",
    "\n",
    "# Create a DataFrame with sorted values\n",
    "df_importances_corrected = pd.DataFrame({\n",
    "    \"Feature\": sorted_feature_names,\n",
    "    \"Importance\": sorted_feature_importances,\n",
    "})\n",
    "\n",
    "df_importances_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Regressor :**\n",
    "- 0\tFeature 3\t0.312523\n",
    "- 1\tFeature 4\t0.139293\n",
    "- 2\tFeature 6\t0.127327\n",
    "- 3\tFeature 0\t0.125569\n",
    "- 4\tFeature 1\t0.089589\n",
    "- 5\tFeature 2\t0.081153\n",
    "- 6\tFeature 7\t0.063125\n",
    "- 7\tFeature 5\t0.061420\n",
    "\n",
    "\n",
    "**Average :**\n",
    "- Feature 3\t1.000000\n",
    "- Feature 0\t0.338262\n",
    "- Feature 4\t0.258449\n",
    "- Feature 6\t0.159238\n",
    "- Feature 1\t0.103561\n",
    "- Feature 2\t0.094906\n",
    "- Feature 7\t0.045719\n",
    "- Feature 5\t0.033224\n",
    "\n",
    "We drop 5, 7, 2, 1 we keep 3, 4, 0, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elmy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
